"""
æ–‡æ¡ˆä¸ªæ€§åŒ–æœåŠ¡
è®°ä½ä½œè€…é£æ ¼è¯åº“ã€å£ç™–ã€å¸¸ç”¨è¡¨æƒ…ã€å›ºå®šæ ç›®
"""

import json
import logging
import re
from typing import Dict, List, Set, Optional, Tuple
from collections import defaultdict, Counter
from pathlib import Path
import pickle
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


class PersonalizedWritingService:
    """ä¸ªæ€§åŒ–æ–‡æ¡ˆç”ŸæˆæœåŠ¡"""
    
    def __init__(self, user_profile_dir: str = "data/user_profiles"):
        self.user_profile_dir = Path(user_profile_dir)
        self.user_profile_dir.mkdir(parents=True, exist_ok=True)
        
        # é»˜è®¤é£æ ¼æ¨¡æ¿
        self.default_styles = {
            'æ²»æ„ˆ': {
                'tone': 'gentle',
                'emoji_style': 'nature',
                'sentence_style': 'flowing',
                'common_phrases': ['å¿ƒåŠ¨ä¸å·²', 'æ²»æ„ˆæ»¡æ»¡', 'å²æœˆé™å¥½', 'æ¸©æŸ”ä»¥å¾…'],
                'emoji_pool': ['ğŸŒ¸', 'ğŸŒ¿', 'âœ¨', 'ğŸ’«', 'ğŸŒ™', 'â˜€ï¸', 'ğŸƒ', 'ğŸŒº']
            },
            'ä¸“ä¸š': {
                'tone': 'informative',
                'emoji_style': 'minimal',
                'sentence_style': 'structured',
                'common_phrases': ['å€¼å¾—æ¨è', 'æ€§ä»·æ¯”é«˜', 'ç»¼åˆè¯„ä»·', 'å®ç”¨æ”»ç•¥'],
                'emoji_pool': ['ğŸ“', 'ğŸ’°', 'â°', 'ğŸš‡', 'ğŸ“', 'â­', 'ğŸ‘', 'ğŸ“Š']
            },
            'è¸©é›·': {
                'tone': 'warning',
                'emoji_style': 'alert',
                'sentence_style': 'direct',
                'common_phrases': ['åƒä¸‡æ³¨æ„', 'é¿é›·æŒ‡å—', 'è¡€æ³ªæ•™è®­', 'çœŸå®ä½“éªŒ'],
                'emoji_pool': ['âš ï¸', 'âŒ', 'ğŸ˜¤', 'ğŸ’”', 'ğŸš«', 'ğŸ˜…', 'ğŸ¤¦â€â™€ï¸', 'ğŸ’¸']
            }
        }
        
        # ä¸ªæ€§åŒ–ç‰¹å¾æƒé‡
        self.personalization_weights = {
            'vocabulary_consistency': 0.25,    # è¯æ±‡ä¸€è‡´æ€§
            'emoji_pattern': 0.20,            # è¡¨æƒ…ç¬¦å·æ¨¡å¼
            'sentence_structure': 0.20,       # å¥å¼ç»“æ„
            'topic_preference': 0.15,         # è¯é¢˜åå¥½
            'tone_consistency': 0.10,         # è¯­è°ƒä¸€è‡´æ€§
            'format_template': 0.10           # æ ¼å¼æ¨¡æ¿
        }
    
    def learn_user_style(self, user_id: str, content_samples: List[Dict]) -> Dict:
        """
        å­¦ä¹ ç”¨æˆ·å†™ä½œé£æ ¼
        
        Args:
            user_id: ç”¨æˆ·ID
            content_samples: ç”¨æˆ·å†å²å†…å®¹æ ·æœ¬
            
        Returns:
            å­¦ä¹ åˆ°çš„é£æ ¼æ¡£æ¡ˆ
        """
        try:
            logger.info(f"å¼€å§‹å­¦ä¹ ç”¨æˆ· {user_id} çš„å†™ä½œé£æ ¼ï¼Œæ ·æœ¬æ•°é‡: {len(content_samples)}")
            
            # 1. æå–è¯æ±‡ç‰¹å¾
            vocabulary_profile = self._analyze_vocabulary_patterns(content_samples)
            
            # 2. åˆ†æè¡¨æƒ…ç¬¦å·ä½¿ç”¨æ¨¡å¼
            emoji_profile = self._analyze_emoji_patterns(content_samples)
            
            # 3. åˆ†æå¥å¼ç»“æ„
            structure_profile = self._analyze_sentence_structures(content_samples)
            
            # 4. åˆ†æè¯é¢˜åå¥½
            topic_profile = self._analyze_topic_preferences(content_samples)
            
            # 5. åˆ†æè¯­è°ƒé£æ ¼
            tone_profile = self._analyze_tone_patterns(content_samples)
            
            # 6. æå–æ ¼å¼æ¨¡æ¿
            format_profile = self._extract_format_templates(content_samples)
            
            # 7. æ„å»ºå®Œæ•´çš„ç”¨æˆ·æ¡£æ¡ˆ
            user_profile = {
                'user_id': user_id,
                'created_at': datetime.now().isoformat(),
                'sample_count': len(content_samples),
                'vocabulary': vocabulary_profile,
                'emoji': emoji_profile,
                'structure': structure_profile,
                'topics': topic_profile,
                'tone': tone_profile,
                'format': format_profile,
                'confidence_score': self._calculate_confidence_score(content_samples)
            }
            
            # 8. ä¿å­˜ç”¨æˆ·æ¡£æ¡ˆ
            self._save_user_profile(user_id, user_profile)
            
            logger.info(f"ç”¨æˆ·é£æ ¼å­¦ä¹ å®Œæˆï¼Œç½®ä¿¡åº¦: {user_profile['confidence_score']:.2f}")
            return user_profile
            
        except Exception as e:
            logger.error(f"ç”¨æˆ·é£æ ¼å­¦ä¹ å¤±è´¥: {e}")
            return {}
    
    def generate_personalized_content(self, user_id: str, content_data: Dict, 
                                    style_override: str = None) -> Dict:
        """
        ç”Ÿæˆä¸ªæ€§åŒ–å†…å®¹
        
        Args:
            user_id: ç”¨æˆ·ID
            content_data: å†…å®¹æ•°æ®ï¼ˆæ•…äº‹çº¿ã€å…³é”®ä¿¡æ¯ç­‰ï¼‰
            style_override: é£æ ¼è¦†ç›–ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ä¸ªæ€§åŒ–çš„å†…å®¹
        """
        try:
            logger.info(f"å¼€å§‹ä¸ºç”¨æˆ· {user_id} ç”Ÿæˆä¸ªæ€§åŒ–å†…å®¹")
            
            # 1. åŠ è½½ç”¨æˆ·æ¡£æ¡ˆ
            user_profile = self._load_user_profile(user_id)
            
            # 2. ç¡®å®šä½¿ç”¨çš„é£æ ¼
            target_style = style_override or self._determine_best_style(user_profile, content_data)
            
            # 3. ç”Ÿæˆä¸ªæ€§åŒ–æ ‡é¢˜
            personalized_title = self._generate_personalized_title(
                content_data, user_profile, target_style
            )
            
            # 4. ç”Ÿæˆä¸ªæ€§åŒ–æ­£æ–‡
            personalized_body = self._generate_personalized_body(
                content_data, user_profile, target_style
            )
            
            # 5. ç”Ÿæˆä¸ªæ€§åŒ–è¯é¢˜æ ‡ç­¾
            personalized_hashtags = self._generate_personalized_hashtags(
                content_data, user_profile, target_style
            )
            
            # 6. æ·»åŠ ä¸ªæ€§åŒ–äº’åŠ¨å¼•å¯¼
            personalized_cta = self._generate_personalized_cta(
                user_profile, target_style
            )
            
            result = {
                'title': personalized_title,
                'body': personalized_body,
                'hashtags': personalized_hashtags,
                'cta': personalized_cta,
                'style_used': target_style,
                'personalization_confidence': user_profile.get('confidence_score', 0.5),
                'metadata': {
                    'user_id': user_id,
                    'generated_at': datetime.now().isoformat(),
                    'personalization_features': self._get_applied_features(user_profile)
                }
            }
            
            logger.info(f"ä¸ªæ€§åŒ–å†…å®¹ç”Ÿæˆå®Œæˆï¼Œé£æ ¼: {target_style}")
            return result
            
        except Exception as e:
            logger.error(f"ä¸ªæ€§åŒ–å†…å®¹ç”Ÿæˆå¤±è´¥: {e}")
            # å›é€€åˆ°é»˜è®¤ç”Ÿæˆ
            return self._generate_default_content(content_data, style_override or 'æ²»æ„ˆ')
    
    def _analyze_vocabulary_patterns(self, samples: List[Dict]) -> Dict:
        """åˆ†æè¯æ±‡æ¨¡å¼"""
        try:
            all_words = []
            phrase_patterns = []
            
            for sample in samples:
                text = sample.get('body', '') + ' ' + sample.get('title', '')
                words = re.findall(r'\b[\u4e00-\u9fff]+\b', text)  # ä¸­æ–‡è¯æ±‡
                all_words.extend(words)
                
                # æå–çŸ­è¯­æ¨¡å¼
                phrases = re.findall(r'[\u4e00-\u9fff]{2,4}', text)
                phrase_patterns.extend(phrases)
            
            # ç»Ÿè®¡è¯é¢‘
            word_freq = Counter(all_words)
            phrase_freq = Counter(phrase_patterns)
            
            # æå–ç‰¹å¾è¯æ±‡
            signature_words = [word for word, freq in word_freq.most_common(20) if freq >= 2]
            signature_phrases = [phrase for phrase, freq in phrase_freq.most_common(15) if freq >= 2]
            
            return {
                'signature_words': signature_words,
                'signature_phrases': signature_phrases,
                'total_vocabulary': len(set(all_words)),
                'vocabulary_diversity': len(set(all_words)) / max(len(all_words), 1),
                'common_word_patterns': word_freq.most_common(10)
            }
            
        except Exception as e:
            logger.error(f"è¯æ±‡æ¨¡å¼åˆ†æå¤±è´¥: {e}")
            return {}
    
    def _analyze_emoji_patterns(self, samples: List[Dict]) -> Dict:
        """åˆ†æè¡¨æƒ…ç¬¦å·æ¨¡å¼"""
        try:
            all_emojis = []
            emoji_positions = {'start': 0, 'middle': 0, 'end': 0}
            
            for sample in samples:
                text = sample.get('body', '') + ' ' + sample.get('title', '')
                
                # æå–è¡¨æƒ…ç¬¦å·
                emojis = re.findall(r'[ğŸ˜€-ğŸ™ğŸŒ€-ğŸ—¿ğŸš€-ğŸ›¿ğŸ‡€-ğŸ‡¿]+', text)
                all_emojis.extend(emojis)
                
                # åˆ†æä½ç½®æ¨¡å¼
                if emojis:
                    text_length = len(text)
                    for emoji in emojis:
                        pos = text.find(emoji) / text_length
                        if pos < 0.2:
                            emoji_positions['start'] += 1
                        elif pos > 0.8:
                            emoji_positions['end'] += 1
                        else:
                            emoji_positions['middle'] += 1
            
            emoji_freq = Counter(all_emojis)
            
            return {
                'favorite_emojis': [emoji for emoji, freq in emoji_freq.most_common(10)],
                'emoji_frequency': len(all_emojis) / max(len(samples), 1),
                'position_preference': max(emoji_positions, key=emoji_positions.get),
                'emoji_diversity': len(set(all_emojis)),
                'usage_pattern': emoji_freq.most_common(5)
            }
            
        except Exception as e:
            logger.error(f"è¡¨æƒ…ç¬¦å·æ¨¡å¼åˆ†æå¤±è´¥: {e}")
            return {}
    
    def _analyze_sentence_structures(self, samples: List[Dict]) -> Dict:
        """åˆ†æå¥å¼ç»“æ„"""
        try:
            sentence_lengths = []
            punctuation_patterns = []
            structure_types = {'declarative': 0, 'exclamatory': 0, 'interrogative': 0}
            
            for sample in samples:
                text = sample.get('body', '')
                
                # åˆ†å¥
                sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', text)
                sentences = [s.strip() for s in sentences if s.strip()]
                
                for sentence in sentences:
                    sentence_lengths.append(len(sentence))
                    
                    # åˆ†æå¥å‹
                    if sentence.endswith('ï¼') or '!' in sentence:
                        structure_types['exclamatory'] += 1
                    elif sentence.endswith('ï¼Ÿ') or '?' in sentence:
                        structure_types['interrogative'] += 1
                    else:
                        structure_types['declarative'] += 1
                    
                    # æ ‡ç‚¹æ¨¡å¼
                    punctuation = re.findall(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š]', sentence)
                    punctuation_patterns.extend(punctuation)
            
            avg_sentence_length = sum(sentence_lengths) / max(len(sentence_lengths), 1)
            punctuation_freq = Counter(punctuation_patterns)
            
            return {
                'avg_sentence_length': avg_sentence_length,
                'preferred_sentence_type': max(structure_types, key=structure_types.get),
                'punctuation_style': punctuation_freq.most_common(3),
                'sentence_variety': len(set(sentence_lengths)) / max(len(sentence_lengths), 1),
                'structure_distribution': structure_types
            }
            
        except Exception as e:
            logger.error(f"å¥å¼ç»“æ„åˆ†æå¤±è´¥: {e}")
            return {}
    
    def _analyze_topic_preferences(self, samples: List[Dict]) -> Dict:
        """åˆ†æè¯é¢˜åå¥½"""
        try:
            topic_keywords = {
                'food': ['ç¾é£Ÿ', 'å¥½åƒ', 'é¤å…', 'èœ', 'å‘³é“', 'åƒ'],
                'scenery': ['é£æ™¯', 'æ™¯è‰²', 'ç¾æ™¯', 'å±±', 'æµ·', 'å¤©ç©º'],
                'experience': ['ä½“éªŒ', 'æ„Ÿå—', 'è§‰å¾—', 'æ„Ÿè§‰', 'å°è±¡'],
                'recommendation': ['æ¨è', 'å»ºè®®', 'å€¼å¾—', 'å¿…é¡»', 'ä¸€å®š'],
                'cost': ['ä»·æ ¼', 'è´¹ç”¨', 'èŠ±è´¹', 'ä¾¿å®œ', 'è´µ', 'æ€§ä»·æ¯”'],
                'transportation': ['äº¤é€š', 'åœ°é“', 'å…¬äº¤', 'æ‰“è½¦', 'æ­¥è¡Œ'],
                'time': ['æ—¶é—´', 'æ—©ä¸Š', 'ä¸‹åˆ', 'æ™šä¸Š', 'å‘¨æœ«', 'èŠ‚å‡æ—¥']
            }
            
            topic_scores = defaultdict(int)
            
            for sample in samples:
                text = sample.get('body', '') + ' ' + sample.get('title', '')
                
                for topic, keywords in topic_keywords.items():
                    for keyword in keywords:
                        topic_scores[topic] += text.count(keyword)
            
            # è®¡ç®—è¯é¢˜åå¥½åˆ†å¸ƒ
            total_mentions = sum(topic_scores.values())
            topic_distribution = {}
            if total_mentions > 0:
                for topic, count in topic_scores.items():
                    topic_distribution[topic] = count / total_mentions
            
            return {
                'preferred_topics': sorted(topic_scores.items(), key=lambda x: x[1], reverse=True)[:5],
                'topic_distribution': topic_distribution,
                'topic_diversity': len([t for t in topic_scores.values() if t > 0])
            }
            
        except Exception as e:
            logger.error(f"è¯é¢˜åå¥½åˆ†æå¤±è´¥: {e}")
            return {}
    
    def _analyze_tone_patterns(self, samples: List[Dict]) -> Dict:
        """åˆ†æè¯­è°ƒæ¨¡å¼"""
        try:
            tone_indicators = {
                'enthusiastic': ['å¤ªæ£’äº†', 'è¶…çº§', 'ç‰¹åˆ«', 'éå¸¸', 'æå…¶', 'ï¼ï¼'],
                'gentle': ['æ¸©æŸ”', 'è½»æŸ”', 'æ…¢æ…¢', 'é™é™', 'æ‚„æ‚„'],
                'professional': ['åˆ†æ', 'è¯„ä¼°', 'å»ºè®®', 'ç»¼åˆ', 'å®¢è§‚'],
                'casual': ['å“ˆå“ˆ', 'å˜»å˜»', 'å‘€', 'å•¦', 'å‘¢', 'å“¦'],
                'warning': ['æ³¨æ„', 'å°å¿ƒ', 'é¿å…', 'åƒä¸‡', 'è­¦å‘Š']
            }
            
            tone_scores = defaultdict(int)
            
            for sample in samples:
                text = sample.get('body', '') + ' ' + sample.get('title', '')
                
                for tone, indicators in tone_indicators.items():
                    for indicator in indicators:
                        tone_scores[tone] += text.count(indicator)
            
            # ç¡®å®šä¸»è¦è¯­è°ƒ
            primary_tone = max(tone_scores, key=tone_scores.get) if tone_scores else 'neutral'
            
            return {
                'primary_tone': primary_tone,
                'tone_scores': dict(tone_scores),
                'tone_consistency': max(tone_scores.values()) / max(sum(tone_scores.values()), 1)
            }
            
        except Exception as e:
            logger.error(f"è¯­è°ƒæ¨¡å¼åˆ†æå¤±è´¥: {e}")
            return {}
    
    def _extract_format_templates(self, samples: List[Dict]) -> Dict:
        """æå–æ ¼å¼æ¨¡æ¿"""
        try:
            format_patterns = []
            
            for sample in samples:
                body = sample.get('body', '')
                
                # æå–ç»“æ„æ¨¡å¼
                lines = body.split('\n')
                structure = []
                
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue
                    
                    if line.startswith('ğŸ“') or 'åœ°ç‚¹' in line:
                        structure.append('location')
                    elif line.startswith('ğŸ’°') or 'ä»·æ ¼' in line or 'è´¹ç”¨' in line:
                        structure.append('cost')
                    elif line.startswith('â°') or 'æ—¶é—´' in line:
                        structure.append('time')
                    elif line.startswith('ğŸœ') or 'ç¾é£Ÿ' in line:
                        structure.append('food')
                    elif line.startswith('âš ï¸') or 'æ³¨æ„' in line or 'é¿é›·' in line:
                        structure.append('warning')
                    else:
                        structure.append('content')
                
                format_patterns.append(structure)
            
            # æ‰¾å‡ºæœ€å¸¸è§çš„æ ¼å¼æ¨¡å¼
            pattern_freq = Counter([tuple(pattern) for pattern in format_patterns])
            most_common_pattern = pattern_freq.most_common(1)[0][0] if pattern_freq else []
            
            return {
                'preferred_structure': list(most_common_pattern),
                'structure_consistency': pattern_freq.most_common(1)[0][1] / max(len(samples), 1) if pattern_freq else 0,
                'format_variations': len(pattern_freq)
            }
            
        except Exception as e:
            logger.error(f"æ ¼å¼æ¨¡æ¿æå–å¤±è´¥: {e}")
            return {}
    
    def _calculate_confidence_score(self, samples: List[Dict]) -> float:
        """è®¡ç®—å­¦ä¹ ç½®ä¿¡åº¦"""
        try:
            # åŸºäºæ ·æœ¬æ•°é‡å’Œè´¨é‡è®¡ç®—ç½®ä¿¡åº¦
            sample_count = len(samples)
            
            # æ ·æœ¬æ•°é‡å› å­
            count_factor = min(sample_count / 10.0, 1.0)
            
            # æ ·æœ¬è´¨é‡å› å­ï¼ˆåŸºäºå†…å®¹é•¿åº¦å’Œå®Œæ•´æ€§ï¼‰
            quality_scores = []
            for sample in samples:
                title_len = len(sample.get('title', ''))
                body_len = len(sample.get('body', ''))
                hashtag_count = len(sample.get('hashtags', []))
                
                quality = min((title_len + body_len) / 200.0, 1.0) * 0.7 + min(hashtag_count / 5.0, 1.0) * 0.3
                quality_scores.append(quality)
            
            quality_factor = sum(quality_scores) / max(len(quality_scores), 1)
            
            # ç»¼åˆç½®ä¿¡åº¦
            confidence = count_factor * 0.6 + quality_factor * 0.4
            return min(confidence, 1.0)
            
        except Exception:
            return 0.5
    
    def _save_user_profile(self, user_id: str, profile: Dict):
        """ä¿å­˜ç”¨æˆ·æ¡£æ¡ˆ"""
        try:
            profile_path = self.user_profile_dir / f"{user_id}_profile.json"
            with open(profile_path, 'w', encoding='utf-8') as f:
                json.dump(profile, f, ensure_ascii=False, indent=2)
            logger.info(f"ç”¨æˆ·æ¡£æ¡ˆå·²ä¿å­˜: {profile_path}")
        except Exception as e:
            logger.error(f"ä¿å­˜ç”¨æˆ·æ¡£æ¡ˆå¤±è´¥: {e}")
    
    def _load_user_profile(self, user_id: str) -> Dict:
        """åŠ è½½ç”¨æˆ·æ¡£æ¡ˆ"""
        try:
            profile_path = self.user_profile_dir / f"{user_id}_profile.json"
            if profile_path.exists():
                with open(profile_path, 'r', encoding='utf-8') as f:
                    profile = json.load(f)
                logger.info(f"ç”¨æˆ·æ¡£æ¡ˆå·²åŠ è½½: {user_id}")
                return profile
            else:
                logger.info(f"ç”¨æˆ·æ¡£æ¡ˆä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {user_id}")
                return {}
        except Exception as e:
            logger.error(f"åŠ è½½ç”¨æˆ·æ¡£æ¡ˆå¤±è´¥: {e}")
            return {}
    
    def _determine_best_style(self, user_profile: Dict, content_data: Dict) -> str:
        """ç¡®å®šæœ€ä½³é£æ ¼"""
        if not user_profile:
            return 'æ²»æ„ˆ'
        
        # åŸºäºç”¨æˆ·æ¡£æ¡ˆçš„è¯­è°ƒåå¥½
        tone_profile = user_profile.get('tone', {})
        primary_tone = tone_profile.get('primary_tone', 'neutral')
        
        # æ˜ å°„è¯­è°ƒåˆ°é£æ ¼
        tone_to_style = {
            'enthusiastic': 'æ²»æ„ˆ',
            'professional': 'ä¸“ä¸š',
            'warning': 'è¸©é›·',
            'gentle': 'æ²»æ„ˆ',
            'casual': 'æ²»æ„ˆ'
        }
        
        return tone_to_style.get(primary_tone, 'æ²»æ„ˆ')
    
    def _generate_personalized_title(self, content_data: Dict, user_profile: Dict, style: str) -> str:
        """ç”Ÿæˆä¸ªæ€§åŒ–æ ‡é¢˜"""
        try:
            # åŸºç¡€æ ‡é¢˜æ¨¡æ¿
            base_templates = {
                'æ²»æ„ˆ': ['{city}æ²»æ„ˆä¹‹æ—…', 'åœ¨{city}çš„ç¾å¥½æ—¶å…‰', '{city}æ…¢ç”Ÿæ´»ä½“éªŒ'],
                'ä¸“ä¸š': ['{city}æ·±åº¦æ”»ç•¥', '{city}å®ç”¨æŒ‡å—', 'è¶…è¯¦ç»†{city}æ”»ç•¥'],
                'è¸©é›·': ['{city}é¿é›·æŒ‡å—', '{city}è¸©é›·å®å½•', 'åƒä¸‡åˆ«åœ¨{city}è¿™æ ·åš']
            }
            
            city = content_data.get('city', 'è¿™é‡Œ')
            templates = base_templates.get(style, base_templates['æ²»æ„ˆ'])
            
            # åº”ç”¨ç”¨æˆ·ä¸ªæ€§åŒ–
            if user_profile:
                vocabulary = user_profile.get('vocabulary', {})
                signature_phrases = vocabulary.get('signature_phrases', [])
                
                # å°è¯•èå…¥ç”¨æˆ·å¸¸ç”¨çŸ­è¯­
                if signature_phrases:
                    personalized_template = f"{signature_phrases[0]}ï¼{city}æ”»ç•¥"
                    return personalized_template
            
            # ä½¿ç”¨é»˜è®¤æ¨¡æ¿
            import random
            return random.choice(templates).format(city=city)
            
        except Exception as e:
            logger.error(f"ä¸ªæ€§åŒ–æ ‡é¢˜ç”Ÿæˆå¤±è´¥: {e}")
            return f"{content_data.get('city', 'è¿™é‡Œ')}æ”»ç•¥"
    
    def _generate_personalized_body(self, content_data: Dict, user_profile: Dict, style: str) -> str:
        """ç”Ÿæˆä¸ªæ€§åŒ–æ­£æ–‡"""
        try:
            # è·å–æ•…äº‹çº¿æ•°æ®
            storyline = content_data.get('storyline', {})
            sections = storyline.get('sections', [])
            tips = storyline.get('tips', [])
            costs = storyline.get('costs', {})
            
            body_parts = []
            
            # å¼€åœºç™½ï¼ˆä¸ªæ€§åŒ–ï¼‰
            if user_profile:
                tone = user_profile.get('tone', {}).get('primary_tone', 'neutral')
                if tone == 'enthusiastic':
                    opening = "ä»Šå¤©çš„ä½“éªŒçœŸçš„å¤ªæ£’äº†ï¼æ¯ä¸€ä¸ªç¬é—´éƒ½è®©äººå¿ƒåŠ¨ä¸å·²"
                elif tone == 'gentle':
                    opening = "é™é™åœ°èµ°è¿‡è¿™äº›åœ°æ–¹ï¼Œå†…å¿ƒå……æ»¡äº†æ¸©æš–å’Œæ„ŸåŠ¨"
                elif tone == 'professional':
                    opening = "ç»è¿‡å®åœ°ä½“éªŒï¼Œä¸ºå¤§å®¶æ•´ç†äº†è¿™ä»½è¯¦ç»†æ”»ç•¥"
                else:
                    opening = "åˆ†äº«ä¸€ä¸‹ä»Šå¤©çš„ç¾å¥½ç»å†"
            else:
                opening = "åˆ†äº«ä¸€ä¸‹ä»Šå¤©çš„ç¾å¥½ç»å†"
            
            body_parts.append(opening)
            
            # è·¯çº¿å®‰æ’ï¼ˆä½¿ç”¨ç”¨æˆ·åå¥½çš„è¡¨æƒ…ç¬¦å·ï¼‰
            if sections and user_profile:
                emoji_profile = user_profile.get('emoji', {})
                favorite_emojis = emoji_profile.get('favorite_emojis', ['ğŸ“'])
                location_emoji = favorite_emojis[0] if favorite_emojis else 'ğŸ“'
                
                route_text = f"{location_emoji}è·¯çº¿å®‰æ’ï¼š"
                for i, section in enumerate(sections[:4]):
                    route_text += f" {section.get('timestamp', f'{i*20:02d}:{0:02d}')} {section.get('title', 'ç²¾å½©æ—¶åˆ»')}"
                    if i < len(sections) - 1:
                        route_text += " â†’"
                route_text += "ï¼Œæ—¶é—´å®‰æ’åˆšåˆšå¥½ä¸ä¼šå¤ªèµ¶"
                body_parts.append(route_text)
            
            # ç¾é£Ÿæ¨èï¼ˆä¸ªæ€§åŒ–è¯­è¨€ï¼‰
            if user_profile:
                vocabulary = user_profile.get('vocabulary', {})
                food_phrases = [p for p in vocabulary.get('signature_phrases', []) if 'å¥½åƒ' in p or 'ç¾å‘³' in p]
                if food_phrases:
                    food_text = f"ğŸœç¾é£Ÿæ¨èï¼š{food_phrases[0]}ï¼Œç‰¹åˆ«æ˜¯é‚£å®¶å°åº—çš„æ‹›ç‰Œèœ"
                else:
                    food_text = "ğŸœç¾é£Ÿæ¨èï¼šæ¯ä¸€å£éƒ½æ˜¯æ»¡æ»¡çš„å¹¸ç¦æ„Ÿï¼Œç‰¹åˆ«æ˜¯é‚£å®¶å°åº—çš„æ‹›ç‰Œèœ"
            else:
                food_text = "ğŸœç¾é£Ÿæ¨èï¼šæ¯ä¸€å£éƒ½æ˜¯æ»¡æ»¡çš„å¹¸ç¦æ„Ÿï¼Œç‰¹åˆ«æ˜¯é‚£å®¶å°åº—çš„æ‹›ç‰Œèœ"
            
            body_parts.append(food_text)
            
            # é¿é›·æé†’
            if tips:
                warning_text = f"âš ï¸è¸©é›·é¿å‘ï¼š{tips[0]}ï¼Œå¤§å®¶å»çš„æ—¶å€™è¦æ³¨æ„"
                body_parts.append(warning_text)
            
            # å®ç”¨ä¿¡æ¯
            cost_info = costs.get('total', '200å…ƒå·¦å³')
            practical_text = f"ğŸ’°å®ç”¨ä¿¡æ¯ï¼šäººå‡{cost_info}ï¼Œä¸€å¤©æ—¶é—´åˆšå¥½ï¼Œå»ºè®®ç©¿èˆ’é€‚çš„é‹å­"
            body_parts.append(practical_text)
            
            return '\n\n'.join(body_parts)
            
        except Exception as e:
            logger.error(f"ä¸ªæ€§åŒ–æ­£æ–‡ç”Ÿæˆå¤±è´¥: {e}")
            return "ä»Šå¤©çš„ä½“éªŒå¾ˆä¸é”™ï¼Œæ¨èå¤§å®¶å»è¯•è¯•ï¼"
    
    def _generate_personalized_hashtags(self, content_data: Dict, user_profile: Dict, style: str) -> List[str]:
        """ç”Ÿæˆä¸ªæ€§åŒ–è¯é¢˜æ ‡ç­¾"""
        try:
            base_hashtags = []
            
            # åŸºç¡€æ ‡ç­¾
            city = content_data.get('city', '')
            if city:
                base_hashtags.extend([f'#{city}', f'#{city}æ—…è¡Œ', f'#{city}æ”»ç•¥'])
            
            # é£æ ¼ç›¸å…³æ ‡ç­¾
            style_hashtags = {
                'æ²»æ„ˆ': ['#æ²»æ„ˆç³»', '#æ…¢ç”Ÿæ´»', '#ç¾å¥½æ—¶å…‰', '#å²æœˆé™å¥½'],
                'ä¸“ä¸š': ['#å®ç”¨æ”»ç•¥', '#æ·±åº¦æ¸¸', '#æ—…è¡ŒæŒ‡å—', '#æ€§ä»·æ¯”'],
                'è¸©é›·': ['#é¿é›·æŒ‡å—', '#çœŸå®ä½“éªŒ', '#è¸©é›·é¢„è­¦', '#è¡€æ³ªæ•™è®­']
            }
            
            base_hashtags.extend(style_hashtags.get(style, style_hashtags['æ²»æ„ˆ']))
            
            # é€šç”¨æ ‡ç­¾
            base_hashtags.extend(['#ä¸€æ—¥æ¸¸', '#æ—…è¡Œæ”»ç•¥', '#åŸå¸‚æ¢ç´¢', '#å‘¨æœ«å»å“ªé‡Œ'])
            
            # ä¸ªæ€§åŒ–æ ‡ç­¾ï¼ˆåŸºäºç”¨æˆ·è¯é¢˜åå¥½ï¼‰
            if user_profile:
                topic_prefs = user_profile.get('topics', {}).get('preferred_topics', [])
                for topic, score in topic_prefs[:3]:
                    if topic == 'food':
                        base_hashtags.extend(['#ç¾é£Ÿæ¢åº—', '#è§…é£Ÿ'])
                    elif topic == 'scenery':
                        base_hashtags.extend(['#ç¾æ™¯', '#é£æ™¯'])
                    elif topic == 'cost':
                        base_hashtags.extend(['#æ€§ä»·æ¯”', '#çœé’±æ”»ç•¥'])
            
            # å»é‡å¹¶é™åˆ¶æ•°é‡
            unique_hashtags = list(dict.fromkeys(base_hashtags))[:12]
            return unique_hashtags
            
        except Exception as e:
            logger.error(f"ä¸ªæ€§åŒ–æ ‡ç­¾ç”Ÿæˆå¤±è´¥: {e}")
            return ['#æ—…è¡Œ', '#æ”»ç•¥', '#æ¨è']
    
    def _generate_personalized_cta(self, user_profile: Dict, style: str) -> str:
        """ç”Ÿæˆä¸ªæ€§åŒ–äº’åŠ¨å¼•å¯¼"""
        try:
            if user_profile:
                tone = user_profile.get('tone', {}).get('primary_tone', 'neutral')
                emoji_profile = user_profile.get('emoji', {})
                favorite_emojis = emoji_profile.get('favorite_emojis', ['ğŸ˜‹'])
                
                if tone == 'enthusiastic':
                    cta = f"è¿˜æœ‰ä»€ä¹ˆå¥½ç©çš„åœ°æ–¹æ¨èå—{favorite_emojis[0] if favorite_emojis else 'ğŸ˜‹'}ï¼å¿«æ¥åˆ†äº«å§"
                elif tone == 'gentle':
                    cta = f"å¦‚æœä½ ä¹Ÿå–œæ¬¢è¿™æ ·çš„åœ°æ–¹ï¼Œæ¬¢è¿ç•™è¨€äº¤æµ{favorite_emojis[0] if favorite_emojis else 'ğŸ’«'}"
                elif tone == 'professional':
                    cta = "æœ‰ä»€ä¹ˆé—®é¢˜æ¬¢è¿åœ¨è¯„è®ºåŒºè®¨è®ºï¼Œæˆ‘ä¼šåŠæ—¶å›å¤"
                else:
                    cta = f"è¿˜æœ‰ä»€ä¹ˆå¥½ç©çš„åœ°æ–¹æ¨èå—{favorite_emojis[0] if favorite_emojis else 'ğŸ˜‹'}ã€‚æ±‚åˆ†äº«"
            else:
                cta = "è¿˜æœ‰ä»€ä¹ˆå¥½ç©çš„åœ°æ–¹æ¨èå—ğŸ˜‹ã€‚æ±‚åˆ†äº«"
            
            return cta
            
        except Exception as e:
            logger.error(f"ä¸ªæ€§åŒ–äº’åŠ¨å¼•å¯¼ç”Ÿæˆå¤±è´¥: {e}")
            return "æ¬¢è¿åˆ†äº«ä½ çš„æƒ³æ³•ï¼"
    
    def _get_applied_features(self, user_profile: Dict) -> List[str]:
        """è·å–åº”ç”¨çš„ä¸ªæ€§åŒ–ç‰¹å¾"""
        features = []
        
        if user_profile.get('vocabulary', {}).get('signature_phrases'):
            features.append('ä¸ªæ€§åŒ–è¯æ±‡')
        if user_profile.get('emoji', {}).get('favorite_emojis'):
            features.append('è¡¨æƒ…ç¬¦å·åå¥½')
        if user_profile.get('tone', {}).get('primary_tone'):
            features.append('è¯­è°ƒé£æ ¼')
        if user_profile.get('topics', {}).get('preferred_topics'):
            features.append('è¯é¢˜åå¥½')
        
        return features
    
    def _generate_default_content(self, content_data: Dict, style: str) -> Dict:
        """ç”Ÿæˆé»˜è®¤å†…å®¹ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        city = content_data.get('city', 'è¿™é‡Œ')
        
        return {
            'title': f'{city}ä¸€æ—¥æ¸¸æ”»ç•¥',
            'body': 'ä»Šå¤©çš„ä½“éªŒå¾ˆä¸é”™ï¼Œåˆ†äº«ç»™å¤§å®¶ä¸€äº›å®ç”¨çš„ä¿¡æ¯å’Œå»ºè®®ã€‚',
            'hashtags': [f'#{city}', '#æ—…è¡Œæ”»ç•¥', '#ä¸€æ—¥æ¸¸'],
            'cta': 'è¿˜æœ‰ä»€ä¹ˆæƒ³äº†è§£çš„å—ï¼Ÿ',
            'style_used': style,
            'personalization_confidence': 0.0,
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'is_fallback': True
            }
        }


# å…¨å±€æœåŠ¡å®ä¾‹
personalized_writing_service = None

def get_personalized_writing_service() -> PersonalizedWritingService:
    """è·å–ä¸ªæ€§åŒ–æ–‡æ¡ˆæœåŠ¡å®ä¾‹"""
    global personalized_writing_service
    if personalized_writing_service is None:
        personalized_writing_service = PersonalizedWritingService()
    return personalized_writing_service
