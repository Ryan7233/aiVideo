"""
å°çº¢ä¹¦ä¸€é”®å‡ºç¨¿æµæ°´çº¿
é¢å‘æ—…è¡Œåšä¸»çš„æ™ºèƒ½å†…å®¹ç”Ÿæˆç³»ç»Ÿ
"""

import json
import re
import logging
from typing import List, Dict, Tuple, Optional, Union
from pathlib import Path
from datetime import datetime
import hashlib
import random

logger = logging.getLogger(__name__)


class PhotoRankingService:
    """ç…§ç‰‡é€‰ä¼˜æœåŠ¡"""
    
    def __init__(self):
        self.aesthetic_keywords = [
            'é£æ™¯', 'å»ºç­‘', 'ç¾é£Ÿ', 'äººç‰©', 'å¤©ç©º', 'å¤•é˜³', 'å¤œæ™¯', 'è¡—é“',
            'landscape', 'architecture', 'food', 'portrait', 'sky', 'sunset'
        ]
        
    def rank_photos(self, photos: List[str], top_k: int = 15) -> List[Dict]:
        """
        ç…§ç‰‡é€‰ä¼˜æ’åº
        
        Args:
            photos: ç…§ç‰‡è·¯å¾„æˆ–URLåˆ—è¡¨
            top_k: è¿”å›å‰kå¼ ç…§ç‰‡
            
        Returns:
            æ’åºåçš„ç…§ç‰‡ä¿¡æ¯
        """
        try:
            ranked_photos = []
            
            for i, photo_path in enumerate(photos):
                # åŸºç¡€è¯„åˆ†ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…å¯æ¥å…¥CLIP/ç¾å­¦æ¨¡å‹ï¼‰
                score = self._calculate_photo_score(photo_path, i)
                
                ranked_photos.append({
                    'photo_id': f'photo_{i:03d}',
                    'path': photo_path,
                    'score': score,
                    'rank': 0,  # å°†åœ¨æ’åºåè®¾ç½®
                    'tags': self._extract_photo_tags(photo_path),
                    'aesthetic_score': score * 0.7,
                    'composition_score': score * 0.8,
                    'uniqueness_score': score * 0.9
                })
            
            # æŒ‰åˆ†æ•°æ’åº
            ranked_photos.sort(key=lambda x: x['score'], reverse=True)
            
            # è®¾ç½®æ’åå¹¶è¿”å›å‰kä¸ª
            for i, photo in enumerate(ranked_photos[:top_k]):
                photo['rank'] = i + 1
            
            return ranked_photos[:top_k]
            
        except Exception as e:
            logger.error(f"ç…§ç‰‡æ’åºå¤±è´¥: {str(e)}")
            return []
    
    def _calculate_photo_score(self, photo_path: str, index: int) -> float:
        """è®¡ç®—ç…§ç‰‡è¯„åˆ†ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            # åŸºäºæ–‡ä»¶åå’Œä½ç½®çš„å¯å‘å¼è¯„åˆ†
            filename = Path(photo_path).name.lower()
            
            base_score = 0.5
            
            # æ–‡ä»¶ååŒ…å«ç¾å­¦å…³é”®è¯
            for keyword in self.aesthetic_keywords:
                if keyword in filename:
                    base_score += 0.1
            
            # æ–‡ä»¶å¤§å°å¯å‘å¼ï¼ˆå‡è®¾æ›´å¤§çš„æ–‡ä»¶è´¨é‡æ›´å¥½ï¼‰
            if Path(photo_path).exists():
                file_size = Path(photo_path).stat().st_size
                size_score = min(file_size / (1024 * 1024), 5.0) / 10.0  # MBè½¬æ¢ä¸º0-0.5åˆ†
                base_score += size_score
            
            # ä½ç½®å¤šæ ·æ€§ï¼ˆé¿å…è¿ç»­ç›¸ä¼¼ç…§ç‰‡ï¼‰
            position_bonus = 0.1 * (1 - (index % 5) / 10)
            base_score += position_bonus
            
            # éšæœºå› å­å¢åŠ å¤šæ ·æ€§
            random_factor = random.uniform(0.8, 1.2)
            
            return min(base_score * random_factor, 1.0)
            
        except Exception:
            return 0.5
    
    def _extract_photo_tags(self, photo_path: str) -> List[str]:
        """æå–ç…§ç‰‡æ ‡ç­¾ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        filename = Path(photo_path).name.lower()
        tags = []
        
        tag_mapping = {
            'food': ['ç¾é£Ÿ', 'é¤å…', 'å°åƒ'],
            'landscape': ['é£æ™¯', 'è‡ªç„¶', 'æ™¯è‰²'],
            'architecture': ['å»ºç­‘', 'å¤å»º', 'ç°ä»£'],
            'portrait': ['äººç‰©', 'è‡ªæ‹', 'åˆå½±'],
            'night': ['å¤œæ™¯', 'ç¯å…‰', 'å¤œæ™š'],
            'street': ['è¡—æ™¯', 'è¡—é“', 'åŸå¸‚']
        }
        
        for eng_tag, cn_tags in tag_mapping.items():
            if eng_tag in filename:
                tags.extend(cn_tags)
        
        return tags[:3]  # æœ€å¤šè¿”å›3ä¸ªæ ‡ç­¾


class StorylineGenerator:
    """æ•…äº‹çº¿ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.section_templates = {
            'opening': ['åˆå°è±¡', 'åˆ°è¾¾', 'ç¬¬ä¸€çœ¼', 'å¼€å§‹æ¢ç´¢'],
            'experience': ['æ ¸å¿ƒä½“éªŒ', 'å¿…æ‰“å¡', 'äº®ç‚¹æ—¶åˆ»', 'ç‰¹è‰²ä½“éªŒ'],
            'food': ['ç¾é£Ÿå‘ç°', 'è§…é£Ÿæ—¶å…‰', 'å‘³è•¾æƒŠå–œ', 'å½“åœ°ç‰¹è‰²'],
            'hidden': ['å°ä¼—å‘ç°', 'æ„å¤–æ”¶è·', 'éšè—å®è—', 'æœ¬åœ°ç§˜å¯†'],
            'ending': ['æ€»ç»“æ„Ÿå—', 'ç¦»åˆ«æ—¶åˆ»', 'å›å‘³æ— ç©·', 'ä¸‹æ¬¡å†æ¥']
        }
    
    def generate_storyline(self, transcript_mmss: List[Dict], notes: str, 
                          city: str = "", date: str = "", style: str = "æ²»æ„ˆ") -> Dict:
        """
        ç”Ÿæˆæ—…è¡Œæ•…äº‹çº¿å¤§çº²
        
        Args:
            transcript_mmss: å¸¦æ—¶é—´æˆ³çš„è½¬å½•æ–‡æœ¬
            notes: ä½œè€…è¦ç‚¹
            city: åŸå¸‚åç§°
            date: æ—¥æœŸ
            style: é£æ ¼ï¼ˆæ²»æ„ˆ/ä¸“ä¸š/è¸©é›·ç­‰ï¼‰
            
        Returns:
            æ•…äº‹çº¿ç»“æ„
        """
        try:
            # åˆ†æè½¬å½•å†…å®¹
            content_analysis = self._analyze_transcript(transcript_mmss)
            
            # è§£æä½œè€…è¦ç‚¹
            parsed_notes = self._parse_notes(notes)
            
            # ç”Ÿæˆæ•…äº‹æ®µè½
            sections = self._generate_sections(content_analysis, parsed_notes, style)
            
            # æå–å®ç”¨ä¿¡æ¯
            tips = self._extract_tips(content_analysis, parsed_notes)
            costs = self._extract_costs(content_analysis, parsed_notes)
            pois = self._extract_pois(content_analysis, parsed_notes, city)
            keywords = self._extract_keywords(content_analysis, parsed_notes, city)
            
            return {
                'city': city,
                'date': date,
                'style': style,
                'sections': sections,
                'tips': tips,
                'costs': costs,
                'pois': pois,
                'keywords': keywords,
                'duration_estimate': self._estimate_duration(sections),
                'highlight_moments': self._identify_highlights(content_analysis)
            }
            
        except Exception as e:
            logger.error(f"æ•…äº‹çº¿ç”Ÿæˆå¤±è´¥: {str(e)}")
            return self._get_fallback_storyline(city, notes)
    
    def _analyze_transcript(self, transcript_mmss: List[Dict]) -> Dict:
        """åˆ†æè½¬å½•å†…å®¹"""
        analysis = {
            'total_duration': 0,
            'segments': [],
            'topics': set(),
            'emotions': [],
            'locations': set(),
            'activities': set()
        }
        
        # å…³é”®è¯æ˜ å°„
        topic_keywords = {
            'food': ['åƒ', 'ç¾é£Ÿ', 'é¤å…', 'å°åƒ', 'å‘³é“', 'å¥½åƒ', 'é¥­', 'èœ'],
            'scenery': ['é£æ™¯', 'æ™¯è‰²', 'ç¾ä¸½', 'æ¼‚äº®', 'å±±', 'æ°´', 'å¤©ç©º', 'å¤•é˜³'],
            'culture': ['æ–‡åŒ–', 'å†å²', 'å¤', 'ä¼ ç»Ÿ', 'åšç‰©é¦†', 'å¯ºåº™', 'å»ºç­‘'],
            'shopping': ['ä¹°', 'è´­ç‰©', 'å•†åº—', 'å¸‚åœº', 'ä¾¿å®œ', 'è´µ', 'ä»·æ ¼'],
            'transport': ['å', 'èµ°', 'å¼€è½¦', 'åœ°é“', 'å…¬äº¤', 'æ‰“è½¦', 'è·¯']
        }
        
        emotion_keywords = {
            'positive': ['å¥½', 'æ£’', 'å–œæ¬¢', 'å¼€å¿ƒ', 'å…´å¥‹', 'æƒŠå–œ', 'æ»¡æ„'],
            'negative': ['ä¸å¥½', 'å¤±æœ›', 'ç´¯', 'è´µ', 'éš¾åƒ', 'å‘', 'åæ‚”'],
            'neutral': ['è¿˜è¡Œ', 'ä¸€èˆ¬', 'æ™®é€š', 'å¯ä»¥', 'å‡‘åˆ']
        }
        
        for segment in transcript_mmss:
            text = segment.get('text', '').lower()
            start_time = segment.get('start', 0)
            end_time = segment.get('end', 0)
            
            # åˆ†æä¸»é¢˜
            for topic, keywords in topic_keywords.items():
                if any(keyword in text for keyword in keywords):
                    analysis['topics'].add(topic)
            
            # åˆ†ææƒ…æ„Ÿ
            for emotion, keywords in emotion_keywords.items():
                if any(keyword in text for keyword in keywords):
                    analysis['emotions'].append({
                        'emotion': emotion,
                        'timestamp': f"{int(start_time//60):02d}:{int(start_time%60):02d}",
                        'text': text[:50]
                    })
            
            analysis['segments'].append({
                'start': start_time,
                'end': end_time,
                'duration': end_time - start_time,
                'text': text,
                'timestamp': f"{int(start_time//60):02d}:{int(start_time%60):02d}"
            })
            
            analysis['total_duration'] = max(analysis['total_duration'], end_time)
        
        return analysis
    
    def _parse_notes(self, notes: str) -> Dict:
        """è§£æä½œè€…è¦ç‚¹"""
        parsed = {
            'key_points': [],
            'locations': [],
            'costs': {},
            'tips': [],
            'avoid': []
        }
        
        lines = notes.split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # è§£æè´¹ç”¨ä¿¡æ¯
            cost_match = re.search(r'(\d+)å…ƒ|(\d+)å—|èŠ±è´¹(\d+)|äººå‡(\d+)', line)
            if cost_match:
                cost = next(g for g in cost_match.groups() if g)
                parsed['costs']['estimated'] = int(cost)
            
            # è§£æåœ°ç‚¹
            if any(word in line for word in ['åœ¨', 'å»', 'åˆ°', 'ä½äº']):
                parsed['locations'].append(line)
            
            # è§£æé¿é›·ç‚¹
            if any(word in line for word in ['é¿å…', 'ä¸è¦', 'æ³¨æ„', 'å‘', 'è¸©é›·']):
                parsed['avoid'].append(line)
            
            # è§£æå»ºè®®
            if any(word in line for word in ['å»ºè®®', 'æ¨è', 'æœ€å¥½', 'tip', 'tips']):
                parsed['tips'].append(line)
            else:
                parsed['key_points'].append(line)
        
        return parsed
    
    def _generate_sections(self, content_analysis: Dict, parsed_notes: Dict, style: str) -> List[Dict]:
        """ç”Ÿæˆæ•…äº‹æ®µè½"""
        sections = []
        total_duration = content_analysis['total_duration']
        segments = content_analysis['segments']
        
        if not segments:
            return self._get_default_sections()
        
        # æŒ‰æ—¶é—´åˆ†é…æ®µè½
        section_count = min(5, len(segments) // 2 + 2)
        time_per_section = total_duration / section_count
        
        section_types = ['opening', 'experience', 'food', 'hidden', 'ending']
        
        for i in range(section_count):
            start_time = i * time_per_section
            end_time = min((i + 1) * time_per_section, total_duration)
            
            # æ‰¾åˆ°æ—¶é—´èŒƒå›´å†…çš„ç‰‡æ®µ
            relevant_segments = [
                seg for seg in segments 
                if seg['start'] >= start_time and seg['end'] <= end_time
            ]
            
            section_type = section_types[min(i, len(section_types) - 1)]
            title_options = self.section_templates[section_type]
            
            sections.append({
                'title': random.choice(title_options),
                'type': section_type,
                'start_time': f"{int(start_time//60):02d}:{int(start_time%60):02d}",
                'end_time': f"{int(end_time//60):02d}:{int(end_time%60):02d}",
                'used_timestamps': [seg['timestamp'] for seg in relevant_segments],
                'content_summary': self._summarize_segments(relevant_segments),
                'shot_suggestions': self._get_shot_suggestions(section_type),
                'style_notes': self._get_style_notes(section_type, style)
            })
        
        return sections
    
    def _get_shot_suggestions(self, section_type: str) -> List[str]:
        """è·å–é•œå¤´å»ºè®®"""
        shot_mapping = {
            'opening': ['å¹¿è§’å…¨æ™¯', 'å»ºç«‹é•œå¤´', 'ç¯å¢ƒå±•ç¤º'],
            'experience': ['ç‰¹å†™é‡ç‚¹', 'åŠ¨æ€è·Ÿæ‹', 'å¤šè§’åº¦åˆ‡æ¢'],
            'food': ['è¿‘æ™¯ç‰¹å†™', 'åˆ¶ä½œè¿‡ç¨‹', 'å“å°ååº”'],
            'hidden': ['å‘ç°é•œå¤´', 'å¯¹æ¯”å±•ç¤º', 'ç»†èŠ‚æ•æ‰'],
            'ending': ['å›é¡¾è’™å¤ªå¥‡', 'æƒ…æ„Ÿç‰¹å†™', 'å‘Šåˆ«é•œå¤´']
        }
        return shot_mapping.get(section_type, ['å¸¸è§„æ‹æ‘„'])
    
    def _get_style_notes(self, section_type: str, style: str) -> str:
        """è·å–é£æ ¼æ³¨é‡Š"""
        style_templates = {
            'æ²»æ„ˆ': 'æ¸©æš–æ²»æ„ˆçš„æ°›å›´ï¼Œæ³¨é‡æƒ…æ„Ÿå…±é¸£',
            'ä¸“ä¸š': 'ä¿¡æ¯å¯†åº¦é«˜ï¼Œå®ç”¨æ€§å¼º',
            'è¸©é›·': 'é‡ç‚¹çªå‡ºé¿å‘æŒ‡å—ï¼Œå¯¹æ¯”æ˜æ˜¾'
        }
        return style_templates.get(style, 'è‡ªç„¶çœŸå®çš„è¡¨è¾¾')
    
    def _extract_tips(self, content_analysis: Dict, parsed_notes: Dict) -> List[Dict]:
        """æå–å®ç”¨å»ºè®®"""
        tips = []
        
        # ä»ç¬”è®°ä¸­æå–
        for tip in parsed_notes['tips']:
            tips.append({
                'type': 'general',
                'content': tip,
                'priority': 'high'
            })
        
        # ä»é¿é›·ç‚¹æå–
        for avoid in parsed_notes['avoid']:
            tips.append({
                'type': 'warning',
                'content': avoid,
                'priority': 'critical'
            })
        
        # ä»è½¬å½•å†…å®¹æ¨æ–­
        if 'transport' in content_analysis['topics']:
            tips.append({
                'type': 'transport',
                'content': 'å»ºè®®æå‰æŸ¥çœ‹äº¤é€šè·¯çº¿',
                'priority': 'medium'
            })
        
        return tips[:5]  # æœ€å¤š5ä¸ªå»ºè®®
    
    def _extract_costs(self, content_analysis: Dict, parsed_notes: Dict) -> Dict:
        """æå–è´¹ç”¨ä¿¡æ¯"""
        costs = parsed_notes['costs'].copy()
        
        # é»˜è®¤é¢„ä¼°
        if not costs:
            costs = {
                'estimated': 200,
                'range': '150-300',
                'category': 'ä¸­ç­‰æ¶ˆè´¹'
            }
        
        return costs
    
    def _extract_pois(self, content_analysis: Dict, parsed_notes: Dict, city: str) -> List[Dict]:
        """æå–å…´è¶£ç‚¹"""
        pois = []
        
        for location in parsed_notes['locations']:
            pois.append({
                'name': location,
                'city': city,
                'category': 'attraction',
                'mentioned_at': '00:00'  # ç®€åŒ–ç‰ˆ
            })
        
        return pois
    
    def _extract_keywords(self, content_analysis: Dict, parsed_notes: Dict, city: str) -> List[str]:
        """æå–å…³é”®è¯"""
        keywords = set()
        
        # åŸå¸‚ç›¸å…³
        if city:
            keywords.add(city)
            keywords.add(f'{city}æ—…è¡Œ')
        
        # ä¸»é¢˜ç›¸å…³
        topic_mapping = {
            'food': ['ç¾é£Ÿ', 'è§…é£Ÿ', 'å½“åœ°ç‰¹è‰²'],
            'scenery': ['é£æ™¯', 'æ‰“å¡', 'æ‹ç…§'],
            'culture': ['æ–‡åŒ–', 'å†å²', 'äººæ–‡'],
            'shopping': ['è´­ç‰©', 'é€›è¡—', 'ä¹°ä¹°ä¹°']
        }
        
        for topic in content_analysis['topics']:
            keywords.update(topic_mapping.get(topic, []))
        
        # é£æ ¼æ ‡ç­¾
        keywords.update(['ä¸€æ—¥æ¸¸', 'æ”»ç•¥', 'æ—…è¡Œæ—¥è®°', 'åŸå¸‚æ¢ç´¢'])
        
        return list(keywords)[:15]
    
    def _get_fallback_storyline(self, city: str, notes: str) -> Dict:
        """è·å–é»˜è®¤æ•…äº‹çº¿"""
        return {
            'city': city,
            'sections': self._get_default_sections(),
            'tips': [{'type': 'general', 'content': 'æå‰åšå¥½è¡Œç¨‹è§„åˆ’', 'priority': 'medium'}],
            'costs': {'estimated': 200},
            'pois': [],
            'keywords': [city, 'æ—…è¡Œ', 'æ”»ç•¥'] if city else ['æ—…è¡Œ']
        }
    
    def _get_default_sections(self) -> List[Dict]:
        """è·å–é»˜è®¤æ®µè½"""
        return [
            {
                'title': 'åˆå°è±¡',
                'type': 'opening',
                'start_time': '00:00',
                'end_time': '02:00',
                'shot_suggestions': ['å¹¿è§’å…¨æ™¯'],
                'style_notes': 'å»ºç«‹æ°›å›´'
            }
        ]
    
    def _summarize_segments(self, segments: List[Dict]) -> str:
        """æ€»ç»“ç‰‡æ®µå†…å®¹"""
        if not segments:
            return "æš‚æ— å†…å®¹"
        
        texts = [seg['text'][:30] for seg in segments]
        return ' | '.join(texts)
    
    def _estimate_duration(self, sections: List[Dict]) -> str:
        """ä¼°ç®—æ¸¸è§ˆæ—¶é•¿"""
        section_count = len(sections)
        if section_count <= 2:
            return "2-3å°æ—¶"
        elif section_count <= 4:
            return "åŠå¤©"
        else:
            return "ä¸€å¤©"
    
    def _identify_highlights(self, content_analysis: Dict) -> List[Dict]:
        """è¯†åˆ«é«˜å…‰æ—¶åˆ»"""
        highlights = []
        
        for emotion in content_analysis['emotions']:
            if emotion['emotion'] == 'positive':
                highlights.append({
                    'timestamp': emotion['timestamp'],
                    'reason': 'æƒ…æ„Ÿé«˜å…‰',
                    'content': emotion['text']
                })
        
        return highlights[:3]


class XiaohongshuDraftGenerator:
    """å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.title_templates = [
            "{city}{duration}æ¸¸ï½œ{highlight}",
            "è¶…è¯¦ç»†ï¼{city}{style}æ”»ç•¥",
            "{city}å¿…æ‰“å¡ï½œ{poi_count}ä¸ªå®è—åœ°ç‚¹",
            "äººå‡{cost}ğŸ’°{city}ä¸€æ—¥æ¸¸æ”»ç•¥",
            "{city}æ—…è¡Œï½œ{weather}{style}è·¯çº¿"
        ]
        
        self.emoji_pool = {
            'food': ['ğŸœ', 'ğŸ¥˜', 'ğŸ±', 'ğŸ¥Ÿ', 'ğŸ²', 'ğŸ˜‹'],
            'scenery': ['ğŸï¸', 'ğŸŒ…', 'ğŸ”ï¸', 'ğŸŒŠ', 'ğŸŒ¸', 'ğŸ“¸'],
            'transport': ['ğŸš‡', 'ğŸšŒ', 'ğŸš—', 'ğŸš¶â€â™€ï¸', 'ğŸ›µ'],
            'money': ['ğŸ’°', 'ğŸ’¸', 'ğŸ’³', 'ğŸ’µ'],
            'time': ['â°', 'ğŸ•', 'â±ï¸', 'ğŸ“…'],
            'tips': ['âš ï¸', 'ğŸ’¡', 'âœ¨', 'ğŸ‘', 'ğŸ“'],
            'location': ['ğŸ“', 'ğŸ—ºï¸', 'ğŸ§­'],
            'positive': ['ğŸ‘', 'ğŸ’¯', 'âœ¨', 'ğŸŒŸ', 'â¤ï¸', 'ğŸ˜']
        }
    
    def generate_draft(self, storyline: Dict, brand_tone: str = "æ²»æ„ˆ", 
                      constraints: Dict = None) -> Dict:
        """
        ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ
        
        Args:
            storyline: æ•…äº‹çº¿æ•°æ®
            brand_tone: å“ç‰Œè°ƒæ€§
            constraints: çº¦æŸæ¡ä»¶
            
        Returns:
            å°çº¢ä¹¦æ–‡æ¡ˆ
        """
        try:
            if constraints is None:
                constraints = {
                    'emoji_density': 0.3,  # è¡¨æƒ…ç¬¦å·å¯†åº¦
                    'paragraph_length': 80,  # æ¯æ®µå­—æ•°
                    'hashtag_count': 12  # è¯é¢˜æ ‡ç­¾æ•°é‡
                }
            
            # ç”Ÿæˆæ ‡é¢˜
            title = self._generate_title(storyline, brand_tone)
            
            # ç”Ÿæˆæ­£æ–‡
            body = self._generate_body(storyline, brand_tone, constraints)
            
            # ç”Ÿæˆè¯é¢˜æ ‡ç­¾
            hashtags = self._generate_hashtags(storyline, constraints['hashtag_count'])
            
            # ç”ŸæˆPOIä¿¡æ¯
            poi_info = self._format_poi_info(storyline.get('pois', []))
            
            return {
                'title': title,
                'body': body,
                'hashtags': hashtags,
                'poi': poi_info,
                'metadata': {
                    'word_count': len(body.replace(' ', '')),
                    'emoji_count': len(re.findall(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]', body)),
                    'paragraph_count': len(body.split('\n\n')),
                    'brand_tone': brand_tone,
                    'generated_at': datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            logger.error(f"æ–‡æ¡ˆç”Ÿæˆå¤±è´¥: {str(e)}")
            return self._get_fallback_draft(storyline)
    
    def _generate_title(self, storyline: Dict, brand_tone: str) -> str:
        """ç”Ÿæˆæ ‡é¢˜"""
        try:
            city = storyline.get('city', 'æŸåŸå¸‚')
            duration = storyline.get('duration_estimate', 'ä¸€æ—¥')
            sections = storyline.get('sections', [])
            costs = storyline.get('costs', {})
            
            # æå–äº®ç‚¹
            highlight = "å¿…æ‰“å¡"
            if sections:
                food_sections = [s for s in sections if s['type'] == 'food']
                if food_sections:
                    highlight = "è§…é£Ÿä¹‹æ—…"
                elif any(s['type'] == 'hidden' for s in sections):
                    highlight = "å°ä¼—è·¯çº¿"
            
            # é€‰æ‹©æ¨¡æ¿
            template = random.choice(self.title_templates)
            
            title = template.format(
                city=city,
                duration=duration,
                highlight=highlight,
                poi_count=len(storyline.get('pois', [])),
                cost=costs.get('estimated', 200),
                style=brand_tone,
                weather="â˜€ï¸"
            )
            
            # ç¡®ä¿æ ‡é¢˜ä¸è¶…è¿‡20å­—
            if len(title) > 20:
                title = f"{city}{duration}æ¸¸æ”»ç•¥"
            
            return title
            
        except Exception:
            return "åŸå¸‚ä¸€æ—¥æ¸¸æ”»ç•¥"
    
    def _generate_body(self, storyline: Dict, brand_tone: str, constraints: Dict) -> str:
        """ç”Ÿæˆæ­£æ–‡"""
        try:
            sections = storyline.get('sections', [])
            tips = storyline.get('tips', [])
            costs = storyline.get('costs', {})
            
            paragraphs = []
            
            # å¼€åœºç™½
            opening = self._generate_opening(storyline, brand_tone)
            paragraphs.append(opening)
            
            # è·¯çº¿äº®ç‚¹
            if sections:
                route_para = self._generate_route_paragraph(sections, brand_tone)
                paragraphs.append(route_para)
            
            # ç¾é£Ÿæ¨è
            food_sections = [s for s in sections if s['type'] == 'food']
            if food_sections:
                food_para = self._generate_food_paragraph(food_sections, brand_tone)
                paragraphs.append(food_para)
            
            # è¸©é›·é¿å‘
            warning_tips = [t for t in tips if t['type'] == 'warning']
            if warning_tips:
                warning_para = self._generate_warning_paragraph(warning_tips, brand_tone)
                paragraphs.append(warning_para)
            
            # å®ç”¨ä¿¡æ¯
            practical_para = self._generate_practical_paragraph(storyline, brand_tone)
            paragraphs.append(practical_para)
            
            # äº’åŠ¨å¼•å¯¼
            interaction = self._generate_interaction_guide(brand_tone)
            paragraphs.append(interaction)
            
            # æ·»åŠ è¡¨æƒ…ç¬¦å·
            body = '\n\n'.join(paragraphs)
            body = self._add_emojis(body, constraints['emoji_density'])
            
            return body
            
        except Exception as e:
            logger.error(f"æ­£æ–‡ç”Ÿæˆå¤±è´¥: {str(e)}")
            return "ä»Šå¤©çš„åŸå¸‚æ¢ç´¢ä¹‹æ—…çœŸçš„è¶…çº§å……å®ï¼"
    
    def _generate_opening(self, storyline: Dict, brand_tone: str) -> str:
        """ç”Ÿæˆå¼€åœºç™½"""
        city = storyline.get('city', 'è¿™åº§åŸå¸‚')
        duration = storyline.get('duration_estimate', 'ä¸€å¤©')
        
        if brand_tone == "æ²»æ„ˆ":
            return f"åœ¨{city}åº¦è¿‡äº†è¶…çº§æ²»æ„ˆçš„{duration}ï¼Œæ¯ä¸€ä¸ªè§’è½éƒ½è®©äººå¿ƒåŠ¨ä¸å·²"
        elif brand_tone == "ä¸“ä¸š":
            return f"è¯¦ç»†è®°å½•{city}{duration}æ¸¸çš„å®Œæ•´æ”»ç•¥ï¼Œä¿¡æ¯é‡å·¨å¤§å»ºè®®æ”¶è—"
        else:
            return f"{city}{duration}æ¸¸å®æµ‹ï¼Œæœ‰æƒŠå–œä¹Ÿæœ‰è¸©é›·ï¼ŒçœŸå®åˆ†äº«ç»™å¤§å®¶"
    
    def _generate_route_paragraph(self, sections: List[Dict], brand_tone: str) -> str:
        """ç”Ÿæˆè·¯çº¿æ®µè½"""
        route_items = []
        for i, section in enumerate(sections[:4], 1):
            title = section['title']
            time = section['start_time']
            route_items.append(f"{time} {title}")
        
        route_text = " â†’ ".join(route_items)
        return f"ğŸ“è·¯çº¿å®‰æ’ï¼š{route_text}ï¼Œæ—¶é—´å®‰æ’åˆšåˆšå¥½ä¸ä¼šå¤ªèµ¶"
    
    def _generate_food_paragraph(self, food_sections: List[Dict], brand_tone: str) -> str:
        """ç”Ÿæˆç¾é£Ÿæ®µè½"""
        if brand_tone == "æ²»æ„ˆ":
            return "ğŸœç¾é£Ÿæ¨èï¼šæ¯ä¸€å£éƒ½æ˜¯æ»¡æ»¡çš„å¹¸ç¦æ„Ÿï¼Œç‰¹åˆ«æ˜¯é‚£å®¶å°åº—çš„æ‹›ç‰Œèœ"
        else:
            return "ğŸœè§…é£Ÿæ”¶è·ï¼šæ‰¾åˆ°äº†å‡ å®¶æ€§ä»·æ¯”è¶…é«˜çš„æœ¬åœ°ç¾é£Ÿï¼Œå‘³é“æ­£å®—ä»·æ ¼å®æƒ "
    
    def _generate_warning_paragraph(self, warning_tips: List[Dict], brand_tone: str) -> str:
        """ç”Ÿæˆé¿å‘æ®µè½"""
        warning_content = warning_tips[0]['content'] if warning_tips else "å‘¨æœ«äººæ¯”è¾ƒå¤š"
        return f"âš ï¸è¸©é›·é¿å‘ï¼š{warning_content}ï¼Œå¤§å®¶å»çš„æ—¶å€™è¦æ³¨æ„"
    
    def _generate_practical_paragraph(self, storyline: Dict, brand_tone: str) -> str:
        """ç”Ÿæˆå®ç”¨ä¿¡æ¯æ®µè½"""
        costs = storyline.get('costs', {})
        duration = storyline.get('duration_estimate', 'ä¸€å¤©')
        
        cost_text = f"äººå‡{costs.get('estimated', 200)}å…ƒ" if costs else "è´¹ç”¨é€‚ä¸­"
        return f"ğŸ’°å®ç”¨ä¿¡æ¯ï¼š{cost_text}ï¼Œ{duration}æ—¶é—´åˆšå¥½ï¼Œå»ºè®®ç©¿èˆ’é€‚çš„é‹å­"
    
    def _generate_interaction_guide(self, brand_tone: str) -> str:
        """ç”Ÿæˆäº’åŠ¨å¼•å¯¼"""
        guides = [
            "ä½ ä»¬è¿˜æœ‰ä»€ä¹ˆæƒ³äº†è§£çš„å—ï¼Ÿè¯„è®ºåŒºå‘Šè¯‰æˆ‘",
            "æœ‰å»è¿‡çš„å°ä¼™ä¼´å—ï¼Ÿåˆ†äº«ä¸€ä¸‹ä½ ä»¬çš„ä½“éªŒå§",
            "è¿˜æœ‰ä»€ä¹ˆå¥½ç©çš„åœ°æ–¹æ¨èå—ï¼Ÿæ±‚åˆ†äº«"
        ]
        return random.choice(guides)
    
    def _add_emojis(self, text: str, density: float) -> str:
        """æ·»åŠ è¡¨æƒ…ç¬¦å·"""
        try:
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
            emoji_count = max(1, int(len(sentences) * density))
            
            # ä¸ºéšæœºå¥å­æ·»åŠ ç›¸å…³è¡¨æƒ…
            for _ in range(emoji_count):
                if not sentences:
                    break
                    
                sentence_idx = random.randint(0, len(sentences) - 1)
                sentence = sentences[sentence_idx]
                
                # æ ¹æ®å†…å®¹é€‰æ‹©è¡¨æƒ…
                emoji = self._select_emoji_for_content(sentence)
                sentences[sentence_idx] = sentence + emoji
            
            return 'ã€‚'.join(sentences)
            
        except Exception:
            return text
    
    def _select_emoji_for_content(self, content: str) -> str:
        """æ ¹æ®å†…å®¹é€‰æ‹©è¡¨æƒ…ç¬¦å·"""
        for category, emojis in self.emoji_pool.items():
            if category == 'food' and any(word in content for word in ['åƒ', 'ç¾é£Ÿ', 'é¤å…']):
                return random.choice(emojis)
            elif category == 'scenery' and any(word in content for word in ['æ™¯', 'ç¾ä¸½', 'æ‹ç…§']):
                return random.choice(emojis)
            elif category == 'money' and any(word in content for word in ['å…ƒ', 'è´¹ç”¨', 'ä»·æ ¼']):
                return random.choice(emojis)
        
        return random.choice(self.emoji_pool['positive'])
    
    def _generate_hashtags(self, storyline: Dict, count: int) -> List[str]:
        """ç”Ÿæˆè¯é¢˜æ ‡ç­¾"""
        hashtags = []
        
        # åŸå¸‚ç›¸å…³
        city = storyline.get('city', '')
        if city:
            hashtags.extend([f'#{city}', f'#{city}æ—…è¡Œ', f'#{city}æ”»ç•¥'])
        
        # åŸºç¡€æ ‡ç­¾
        base_tags = ['#ä¸€æ—¥æ¸¸', '#æ—…è¡Œæ”»ç•¥', '#åŸå¸‚æ¢ç´¢', '#å‘¨æœ«å»å“ªé‡Œ']
        hashtags.extend(base_tags)
        
        # ä¸»é¢˜æ ‡ç­¾
        sections = storyline.get('sections', [])
        if any(s['type'] == 'food' for s in sections):
            hashtags.extend(['#ç¾é£Ÿæ¢åº—', '#è§…é£Ÿ'])
        if any(s['type'] == 'hidden' for s in sections):
            hashtags.extend(['#å°ä¼—æ™¯ç‚¹', '#éšè—å®è—'])
        
        # è´¹ç”¨ç›¸å…³
        costs = storyline.get('costs', {})
        if costs.get('estimated', 0) < 150:
            hashtags.append('#ç©·æ¸¸')
        elif costs.get('estimated', 0) < 300:
            hashtags.append('#æ€§ä»·æ¯”')
        
        # é£æ ¼æ ‡ç­¾
        hashtags.extend(['#æ—…è¡Œæ—¥è®°', '#æ‰“å¡', '#æ‹ç…§'])
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_hashtags = list(dict.fromkeys(hashtags))  # ä¿æŒé¡ºåºå»é‡
        return unique_hashtags[:count]
    
    def _format_poi_info(self, pois: List[Dict]) -> List[Dict]:
        """æ ¼å¼åŒ–POIä¿¡æ¯"""
        formatted_pois = []
        
        for poi in pois:
            formatted_pois.append({
                'name': poi.get('name', ''),
                'category': poi.get('category', 'attraction'),
                'city': poi.get('city', ''),
                'rating': 4.5,  # é»˜è®¤è¯„åˆ†
                'tips': 'å€¼å¾—ä¸€å»'
            })
        
        return formatted_pois
    
    def _get_fallback_draft(self, storyline: Dict) -> Dict:
        """è·å–é»˜è®¤æ–‡æ¡ˆ"""
        city = storyline.get('city', 'æŸåŸå¸‚')
        return {
            'title': f'{city}ä¸€æ—¥æ¸¸æ”»ç•¥',
            'body': f'ä»Šå¤©åœ¨{city}åº¦è¿‡äº†å……å®çš„ä¸€å¤©ï¼Œåˆ†äº«ç»™å¤§å®¶ä¸€äº›å®ç”¨çš„æ”»ç•¥',
            'hashtags': [f'#{city}', '#æ—…è¡Œæ”»ç•¥', '#ä¸€æ—¥æ¸¸'],
            'poi': []
        }


# å…¨å±€æœåŠ¡å®ä¾‹
photo_ranking_service = None
storyline_generator = None
draft_generator = None

def get_photo_ranking_service() -> PhotoRankingService:
    """è·å–ç…§ç‰‡æ’åºæœåŠ¡å®ä¾‹"""
    global photo_ranking_service
    if photo_ranking_service is None:
        photo_ranking_service = PhotoRankingService()
    return photo_ranking_service

def get_storyline_generator() -> StorylineGenerator:
    """è·å–æ•…äº‹çº¿ç”Ÿæˆå™¨å®ä¾‹"""
    global storyline_generator
    if storyline_generator is None:
        storyline_generator = StorylineGenerator()
    return storyline_generator

def get_draft_generator() -> XiaohongshuDraftGenerator:
    """è·å–æ–‡æ¡ˆç”Ÿæˆå™¨å®ä¾‹"""
    global draft_generator
    if draft_generator is None:
        draft_generator = XiaohongshuDraftGenerator()
    return draft_generator
